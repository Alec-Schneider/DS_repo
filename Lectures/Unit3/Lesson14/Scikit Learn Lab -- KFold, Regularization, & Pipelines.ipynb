{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab: KFold, Regularization, & Pipelines\n",
    "\n",
    "Welcome!  This lab is going to introduce us to some very important aspects of data processing and model building.  \n",
    "\n",
    "Specifically, it's going to go over the following:\n",
    "\n",
    " - **KFold Cross Validation:** This is a more thorough way of choosing your validation set to give you a better idea of how your model might perform under various circumstances within your training data.\n",
    " - **Regularization:** This is an evergreen technique for dealing with models that are overfit (ie, higher scores on training vs. test data).  Regularized linear models are often much better prepared to handle messy data & outliers when using this technique.\n",
    " - **Pipelines:** (Time permitting!) This is an underappreciated aspect of the Scikit-Learn api that allows you to chain together multiple data processing steps, making it much easier to test different models and work seamlessly between your training & test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This lab builds off of the one performed in the last class.  As such, it might be easier just to keep working in your previous lab to answer these questions.  It assumes you already have your data processed from the iowa housing lab.  \n",
    "\n",
    "The questions are listed here just to make the separation of concerns easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: How Does Your Validation Score Differ Using KFold Cross Validation?\n",
    "\n",
    "Take a look at the validation score you got from your previous exercise.  \n",
    "\n",
    "This time, run your model through KFold cross validation using `cross_val_score`.  Is your total validation score appreciably different?  What were your highest and lowest values?\n",
    "\n",
    "What if you changed your number of folds?  Try using 5, 10, & 25 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here# these are the steps from the previous lab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test  = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# your answer here\n",
    "y = train['SalePrice']\n",
    "train.drop('SalePrice', axis=1, inplace=True)\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "train_empty = train.loc[:, train.isnull().sum() > 0]\n",
    "# grab the columns\n",
    "cols = train_empty.columns.tolist()\n",
    "# fill with the appropriate value  -- NA, Other, could also work\n",
    "train[['GarageType', 'GarageFinish']] = train[['GarageType', 'GarageFinish']].fillna('None')\n",
    "test[['GarageType', 'GarageFinish']]  = test[['GarageType', 'GarageFinish']].fillna('None')\n",
    "\n",
    "# we'll use this for GarageYrBlt since it's a numeric column\n",
    "train['GarageYrBlt'].fillna(0, inplace=True)\n",
    "test['GarageYrBlt'].fillna(0, inplace=True)\n",
    "\n",
    "# finding the values to use in the training set\n",
    "ms_mode   = train['MSZoning'].mode()[0]\n",
    "gcarsmean = train['GarageCars'].mean()\n",
    "\n",
    "# and applying them to the test set\n",
    "test['MSZoning'].fillna(ms_mode, inplace=True)\n",
    "test['GarageCars'].fillna(gcarsmean, inplace=True)\n",
    "\n",
    "# your code here\n",
    "# we'll assume the GarageFinish is ordinal.  Ie, FinishedGarage > Unfinished Garage\n",
    "garage_mapping = {\n",
    "    'None': 0, # no garage\n",
    "    'Unf' : 1, # unfinished garage\n",
    "    'RFn' : 2, # partially finished garage\n",
    "    'Fin' : 3  # finished garage\n",
    "}\n",
    "\n",
    "train['GarageFinish'] = train['GarageFinish'].map(garage_mapping)\n",
    "test['GarageFinish']  = test['GarageFinish'].map(garage_mapping)\n",
    "\n",
    "# MSSubClass is really a category, moreso than a true number\n",
    "# so we'll add it to the list of items to be encoded\n",
    "train['MSSubClass'] = train['MSSubClass'].astype(str)\n",
    "test['MSSubClass']  = test['MSSubClass'].astype(str)\n",
    "\n",
    "# concatenate and encode\n",
    "master = pd.concat([train, test])\n",
    "master = pd.get_dummies(master)\n",
    "\n",
    "# drop MSSubClass150\n",
    "master.drop('MSSubClass_150', axis=1, inplace=True)\n",
    "\n",
    "# and split back apart\n",
    "train  = master.iloc[:1460].copy()\n",
    "test   = master.iloc[1460:].copy()\n",
    "\n",
    "# save these values, to use on both your training and test set\n",
    "train_means = train.mean()\n",
    "train_stds  = train.std()\n",
    "\n",
    "# standardize the training set\n",
    "train -= train_means\n",
    "train /= train_stds\n",
    "\n",
    "# and do the same for the test set\n",
    "test -= train_means\n",
    "test /= train_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    208500\n",
       "1    181500\n",
       "2    223500\n",
       "3    140000\n",
       "4    250000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea.1</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <th>Neighborhood_Timber</th>\n",
       "      <th>Neighborhood_Veenker</th>\n",
       "      <th>GarageType_2Types</th>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <th>GarageType_Basment</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>GarageType_CarPort</th>\n",
       "      <th>GarageType_Detchd</th>\n",
       "      <th>GarageType_None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207071</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>1.050634</td>\n",
       "      <td>0.370207</td>\n",
       "      <td>-0.793162</td>\n",
       "      <td>1.161454</td>\n",
       "      <td>0.370207</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>1.227165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131946</td>\n",
       "      <td>-0.163415</td>\n",
       "      <td>-0.087099</td>\n",
       "      <td>-0.064216</td>\n",
       "      <td>0.823223</td>\n",
       "      <td>-0.114788</td>\n",
       "      <td>-0.253172</td>\n",
       "      <td>-0.07873</td>\n",
       "      <td>-0.600353</td>\n",
       "      <td>-0.242277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091855</td>\n",
       "      <td>-0.071812</td>\n",
       "      <td>2.178881</td>\n",
       "      <td>0.156680</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.257052</td>\n",
       "      <td>-0.794891</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>-0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131946</td>\n",
       "      <td>-0.163415</td>\n",
       "      <td>11.473319</td>\n",
       "      <td>-0.064216</td>\n",
       "      <td>0.823223</td>\n",
       "      <td>-0.114788</td>\n",
       "      <td>-0.253172</td>\n",
       "      <td>-0.07873</td>\n",
       "      <td>-0.600353</td>\n",
       "      <td>-0.242277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073455</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>0.984415</td>\n",
       "      <td>0.514836</td>\n",
       "      <td>-0.627611</td>\n",
       "      <td>1.188943</td>\n",
       "      <td>0.514836</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>1.227165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131946</td>\n",
       "      <td>-0.163415</td>\n",
       "      <td>-0.087099</td>\n",
       "      <td>-0.064216</td>\n",
       "      <td>0.823223</td>\n",
       "      <td>-0.114788</td>\n",
       "      <td>-0.253172</td>\n",
       "      <td>-0.07873</td>\n",
       "      <td>-0.600353</td>\n",
       "      <td>-0.242277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.096864</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>-1.862993</td>\n",
       "      <td>0.383528</td>\n",
       "      <td>-0.521555</td>\n",
       "      <td>0.936955</td>\n",
       "      <td>0.383528</td>\n",
       "      <td>-1.025689</td>\n",
       "      <td>-0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131946</td>\n",
       "      <td>-0.163415</td>\n",
       "      <td>-0.087099</td>\n",
       "      <td>-0.064216</td>\n",
       "      <td>-1.213905</td>\n",
       "      <td>-0.114788</td>\n",
       "      <td>-0.253172</td>\n",
       "      <td>-0.07873</td>\n",
       "      <td>1.664545</td>\n",
       "      <td>-0.242277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375020</td>\n",
       "      <td>1.374324</td>\n",
       "      <td>-0.517023</td>\n",
       "      <td>0.951306</td>\n",
       "      <td>1.298881</td>\n",
       "      <td>-0.045596</td>\n",
       "      <td>1.617323</td>\n",
       "      <td>1.298881</td>\n",
       "      <td>0.789470</td>\n",
       "      <td>1.227165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131946</td>\n",
       "      <td>-0.163415</td>\n",
       "      <td>-0.087099</td>\n",
       "      <td>-0.064216</td>\n",
       "      <td>0.823223</td>\n",
       "      <td>-0.114788</td>\n",
       "      <td>-0.253172</td>\n",
       "      <td>-0.07873</td>\n",
       "      <td>-0.600353</td>\n",
       "      <td>-0.242277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  OverallCond  YearBuilt  GrLivArea  1stFlrSF  \\\n",
       "0 -0.207071     0.651256    -0.517023   1.050634   0.370207 -0.793162   \n",
       "1 -0.091855    -0.071812     2.178881   0.156680  -0.482347  0.257052   \n",
       "2  0.073455     0.651256    -0.517023   0.984415   0.514836 -0.627611   \n",
       "3 -0.096864     0.651256    -0.517023  -1.862993   0.383528 -0.521555   \n",
       "4  0.375020     1.374324    -0.517023   0.951306   1.298881 -0.045596   \n",
       "\n",
       "   2ndFlrSF  GrLivArea.1  FullBath  HalfBath  ...  Neighborhood_StoneBr  \\\n",
       "0  1.161454     0.370207  0.789470  1.227165  ...             -0.131946   \n",
       "1 -0.794891    -0.482347  0.789470 -0.761360  ...             -0.131946   \n",
       "2  1.188943     0.514836  0.789470  1.227165  ...             -0.131946   \n",
       "3  0.936955     0.383528 -1.025689 -0.761360  ...             -0.131946   \n",
       "4  1.617323     1.298881  0.789470  1.227165  ...             -0.131946   \n",
       "\n",
       "   Neighborhood_Timber  Neighborhood_Veenker  GarageType_2Types  \\\n",
       "0            -0.163415             -0.087099          -0.064216   \n",
       "1            -0.163415             11.473319          -0.064216   \n",
       "2            -0.163415             -0.087099          -0.064216   \n",
       "3            -0.163415             -0.087099          -0.064216   \n",
       "4            -0.163415             -0.087099          -0.064216   \n",
       "\n",
       "   GarageType_Attchd  GarageType_Basment  GarageType_BuiltIn  \\\n",
       "0           0.823223           -0.114788           -0.253172   \n",
       "1           0.823223           -0.114788           -0.253172   \n",
       "2           0.823223           -0.114788           -0.253172   \n",
       "3          -1.213905           -0.114788           -0.253172   \n",
       "4           0.823223           -0.114788           -0.253172   \n",
       "\n",
       "   GarageType_CarPort  GarageType_Detchd  GarageType_None  \n",
       "0            -0.07873          -0.600353        -0.242277  \n",
       "1            -0.07873          -0.600353        -0.242277  \n",
       "2            -0.07873          -0.600353        -0.242277  \n",
       "3            -0.07873           1.664545        -0.242277  \n",
       "4            -0.07873          -0.600353        -0.242277  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "cvs = [5, 10, 25]\n",
    "cv5 = cross_val_score(lr, X=train, y=y, cv=cvs[0])\n",
    "cv10 = cross_val_score(lr, X=train, y=y, cv=cvs[1])\n",
    "cv25 = cross_val_score(lr, X=train, y=y, cv=cvs[2])\n",
    "cv_scores = [cross_val_score(lr, X=train, y=y, cv=i) for i in cvs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold CV:\n",
      "-------------------------\n",
      "[0.8672403  0.82996498 0.82988874 0.82259029 0.73647959]\n",
      "\n",
      "\n",
      "0.7364795903283214 0.8672403027527855 0.04329622420683497\n",
      "10 fold CV:\n",
      "-------------------------\n",
      "[0.8698292  0.86872385 0.90039109 0.77416761 0.82789523 0.83483228\n",
      " 0.81937276 0.81978263 0.6624736  0.85162283]\n",
      "\n",
      "\n",
      "0.662473603885437 0.9003910944086757 0.06279570903763354\n",
      "25 fold CV:\n",
      "-------------------------\n",
      "[0.89169958 0.82401953 0.8775956  0.86142958 0.90050608 0.90731896\n",
      " 0.89265571 0.81764167 0.74547212 0.79276342 0.87300321 0.80286892\n",
      " 0.81504411 0.82404576 0.91093031 0.7844823  0.87247875 0.84910225\n",
      " 0.76934216 0.81469008 0.74870837 0.86497941 0.11783357 0.87003587\n",
      " 0.87715818]\n",
      "\n",
      "\n",
      "0.11783356871476669 0.9109303091746784 0.14955288003945627\n"
     ]
    }
   ],
   "source": [
    "print('5 fold CV:', '-'*25, cv5, '\\n', sep='\\n')\n",
    "print(cv5.min(), cv5.max(), cv5.std())\n",
    "print('10 fold CV:', '-'*25, cv10, '\\n', sep='\\n')\n",
    "print(cv10.min(), cv10.max(), cv10.std())\n",
    "print('25 fold CV:', '-'*25, cv25, '\\n', sep='\\n')\n",
    "print(cv25.min(), cv25.max(), cv25.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvdict = {}\n",
    "for cv, fold in zip(cvs, cv_scores):\n",
    "    cvdict[cv] = fold.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 0.8172327811582084, 10: 0.8229091090102086, 25: 0.8122322198428682}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18203fbd358>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig, ax = plt.subplots(3, figsize=(8,8))\n",
    "np.log(y).hist(ax=ax[0])\n",
    "np.log10(y).hist(ax=ax[1])\n",
    "y.hist(ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_log = [cross_val_score(lr, X=train, y=np.log(y), cv=i) for i in cvs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: {'mean': 0.8650290415468866, 'median': 0.8697462682984962, 'std': 0.028310257006966204}, 10: {'mean': 0.8628872554110364, 'median': 0.8750473805855438, 'std': 0.051933884093512926}, 25: {'mean': 0.8618427057374928, 'median': 0.8825837190524161, 'std': 0.08323319826071719}}\n"
     ]
    }
   ],
   "source": [
    "cv_log_dict = {}\n",
    "for folds, scores in zip(cvs, cv_scores_log):\n",
    "    cv_log_dict[folds] = {'mean': scores.mean(),\n",
    "                          'median': np.median(scores),\n",
    "                          'std': scores.std()}\n",
    "    \n",
    "print(cv_log_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Updating Your Model With Ridge & Lasso Regression\n",
    "\n",
    "Instead of using Linear Regression, import `Ridge` or `Lasso`, and use cross validation to find the ideal value of alpha.  \n",
    "\n",
    "Some basic tips:\n",
    "\n",
    "For values of alpha try this:  `alphas = np.logspace(-4, 4, 9)`\n",
    "Then write a `for-loop` that generically goes like this:\n",
    "\n",
    "`for value in alphas:\n",
    "    1). set value of alpha to current value using set_params() method\n",
    "    2). pass in instance of Ridge or Lasso into cross_val_score\n",
    "    3). using a tuple, append the average of all results from step 2 into a list, along with the value of alpha`\n",
    "    \n",
    "When you're finished, you should have a list that has 9 tuples inside it, each one with the average cross validation score as well as the value of alpha associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02621377476420861, tolerance: 0.02100187174002019\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-4, 4, num=9)\n",
    "lasso_scores = []\n",
    "ridge_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.set_params(alpha=alpha)\n",
    "    lasso_scores.append((cross_val_score(lasso, train, np.log(y), cv=10).mean(), alpha))\n",
    "    ridge.set_params(alpha=alpha)\n",
    "    ridge_scores.append((cross_val_score(ridge, X=train, y=np.log(y), cv=10).mean(), alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8634425048822774, 0.0001), (0.864191084904902, 0.001), (0.8544354808965491, 0.01), (0.6909458322110515, 0.1), (-0.007368842975429635, 1.0), (-0.007368842975429635, 10.0), (-0.007368842975429635, 100.0), (-0.007368842975429635, 1000.0), (-0.007368842975429635, 10000.0)]\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(*lasso_scores, sep='\\n')\n",
    "print(max(lasso_scores)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8628836012707453, 0.0001)\n",
      "(0.8628843968787981, 0.001)\n",
      "(0.862892212874151, 0.01)\n",
      "(0.8629586815873479, 0.1)\n",
      "(0.8632282377170221, 1.0)\n",
      "(0.8637818510552357, 10.0)\n",
      "(0.8652092706925322, 100.0)\n",
      "(0.8442515828165693, 1000.0)\n",
      "(0.584125235255362, 10000.0)\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(*ridge_scores, sep='\\n')\n",
    "print(max(ridge_scores)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:** In Scikit-Learn cross validation is sometimes built into algorithms automatically.  Luckily this is the case with `Ridge` and `Lasso`.  If you're inclined to take a look at the `RidgeCV` and `LassoCV` methods, you can basically combine what we just did into one step.\n",
    "\n",
    "**Note:** These aren't always available, and they don't always work in the same way, so remember that they won't always be an option.\n",
    "\n",
    "**RidgeCV:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html\n",
    "**LassoCV:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Building A Pipeline\n",
    "\n",
    "Let's try building some pipelines to test out different versions of our models more easily.  \n",
    "\n",
    "For this one, we are going to start fresh a little bit to get the hang of using our pipelines, and to go through the entire process.\n",
    "\n",
    "So......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Reload the training and test sets\n",
    "\n",
    " - create a new variable for `y`, and set it equal to the log of `SalePrice`\n",
    " - create a variable for the `id` column in the test set -- this will be reused later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('SalePrice', axis=1)\n",
    "y = train['SalePrice']\n",
    "y = np.log(y)\n",
    "X.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Fill in the missing data on training & test\n",
    "\n",
    "**Note:** If you feel like you have a good handle on this, you can just copy and paste from your previous solutions or the lab manual.  \n",
    "\n",
    "If you have the time and think you need extra practice, feel free to try and re-create the results on your own.....just be mindful of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_empty = train.loc[:, train.isnull().sum() > 0]\n",
    "col = X_empty.columns.to_list()\n",
    "\n",
    "X[['GarageType', 'GarageFinish']] = X[['GarageType', 'GarageFinish']].fillna('None')\n",
    "test[['GarageType', 'GarageFinish']] = test[['GarageType', 'GarageFinish']].fillna('None')\n",
    "\n",
    "X['GarageYrBlt'].fillna(0, inplace=True)\n",
    "test['GarageYrBlt'].fillna(0, inplace=True)\n",
    "\n",
    "# finding the values to use in the training set\n",
    "ms_mode   = X['MSZoning'].mode()[0]\n",
    "gcarsmean = X['GarageCars'].mean()\n",
    "\n",
    "# and applying them to the test set\n",
    "test['MSZoning'].fillna(ms_mode, inplace=True)\n",
    "test['GarageCars'].fillna(gcarsmean, inplace=True)\n",
    "\n",
    "# your code here\n",
    "# we'll assume the GarageFinish is ordinal.  Ie, FinishedGarage > Unfinished Garage\n",
    "# garage_mapping = {\n",
    "#     'None': 0, # no garage\n",
    "#     'Unf' : 1, # unfinished garage\n",
    "#     'RFn' : 2, # partially finished garage\n",
    "#     'Fin' : 3  # finished garage\n",
    "# }\n",
    "\n",
    "# X['GarageFinish'] = X['GarageFinish'].map(garage_mapping)\n",
    "# test['GarageFinish']  = test['GarageFinish'].map(garage_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Reclassify the `MSSubClass` column as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSSubClass is really a category, moreso than a true number\n",
    "# so we'll add it to the list of items to be encoded\n",
    "X['MSSubClass'] = X['MSSubClass'].astype(str)\n",
    "test['MSSubClass']  = test['MSSubClass'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Create Your Pipeline!\n",
    "\n",
    "\n",
    "a). Initialize instances for each of the following items:\n",
    "\n",
    " - An ordinal encoder for the `GarageFinish` column (be careful about the mapping dictionary here)\n",
    " - A categorical encoder for your nominal columns\n",
    " - The standard scaler\n",
    " - Lasso or Ridge regression, with the cross validated value of alpha from the previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'col': 'GarageFinish',\n",
    "    'mapping': {\n",
    "        'None': 0, # no garage\n",
    "        'Unf' : 1, # unfinished garage\n",
    "        'RFn' : 2, # partially finished garage\n",
    "        'Fin' : 3  # finished garage\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "sc = StandardScaler()\n",
    "ore = ce.OrdinalEncoder(cols=['GarageFinish'], mapping=[mapping])\n",
    "ohe = ce.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ore, ohe, sc, ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform the oridinal columns with the ordincal encoder\n",
    "# ore.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['GarageFinish'], drop_invariant=False,\n",
       "                                handle_missing='value', handle_unknown='value',\n",
       "                                mapping=[{'col': 'GarageFinish',\n",
       "                                          'mapping': {'Fin': 3, 'None': 0,\n",
       "                                                      'RFn': 2, 'Unf': 1}}],\n",
       "                                return_df=True, verbose=0)),\n",
       "                ('onehotencoder',\n",
       "                 OneHotEncoder(cols=['MSSubClass', 'MSZoning', 'Neighborhood',\n",
       "                                     'GarageType'],\n",
       "                               drop_invariant=False, handle_missing='value',\n",
       "                               handle_unknown='value', return_df=True,\n",
       "                               use_cat_names=False, verbose=0)),\n",
       "                ('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('ridge',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87437439, 0.91234571, 0.91290423, 0.82657394, 0.86676275,\n",
       "       0.86542806, 0.8769858 , 0.89144589, 0.72653906, 0.87891162])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X=X, y=y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-3, 3, 7)\n",
    "cv_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    pipe.steps[-1][1].set_params(alpha=alpha)\n",
    "    scores = cross_val_score(estimator=pipe, X=X, y=y, cv=10)\n",
    "    cv_scores.append((np.mean(scores), alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8628844021672876, 0.001),\n",
       " (0.8628922631891338, 0.01),\n",
       " (0.8629589887467667, 0.1),\n",
       " (0.8632271451896907, 1.0),\n",
       " (0.8637652063955132, 10.0),\n",
       " (0.8651023941990363, 100.0),\n",
       " (0.8445309718475507, 1000.0)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8651023941990363, 100.0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Fit the pipeline on your training set, and predict the values on your test set\n",
    "\n",
    " - to get the \"real\" values of your prediction you would use the function `np.exp()`\n",
    " \n",
    "ie, if `pipe.predict(test)` gives you the predicted log values of your test set, then `np.exp(pipe.predict(test))` would give you the actual expected housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117757.19893444, 153765.15486921, 170628.65553705, ...,\n",
       "       150764.80850924, 117678.20922137, 226557.41950875])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps[-1][1].set_params(alpha=max(cv_scores)[1])\n",
    "\n",
    "np.exp(pipe.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
